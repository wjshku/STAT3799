---
title: "Stat3799 Simulation"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(Deriv)
library(ggplot2)
library(hrbrthemes)
```

1. General Setup and Testing

```{r}
alpha <- function(n, h, x, X, Y, k){
  temp <- 0
  for(i in 1:length(X)){
    temp <- temp + Y[i] * k((x - X[i])/h)/(n*h)
  }
  return(temp)
}

valpha <- Vectorize(alpha,SIMPLIFY = FALSE)

phat<- function(n, h, x, X, k){
  temp <- sum(k((x - X)/h)/(n*h))
  return(max(temp,0.001)) #this is to prevent the estimation from resulting in NA
}

vphat<- Vectorize(phat)

mhat <- function(n, h, x, X, Y, k){
  return(alpha(n,h,x,X,Y,k)/phat(n,h,x,X,k))
}

vmhat <- function(n, h, x, X, Y, k){
  return(valpha(n,h,x,X,Y,k)/vphat(n,h,x,X,k))
}

beta <- function(n, h, x, X, Y, k, m, g, Xu){
  Yu <- 1:length(Xu)
  for(i in 1:length(Xu)){
    Yu[i] <- mhat(n, h, Xu[i], X, Y, k)
  }
  return(alpha(m,g,x,Xu,Yu,k))
}

rhat <- function(n, h, x, X, Y, k, m, g, Xu){
  return(beta(n, h, x, X, Y, k, m, g, Xu)/phat(m,g,x,Xu,k))
}
```

Simulation functions
```{r}
simu_unif <- function(multi, n, xmax, sigmaep = 1){

    X <- runif(n*multi,xmax)
    Y <- mx(X) + rnorm(n*multi, sd = sigmaep)

  return(data.frame(X, Y))
}

simu_norm <- function(multi, n, meanx, sigmax, sigmaep = 1){

    X <- rnorm(n*multi,mean = meanx,sd = sigmax)
    Y <- mx(X) + rnorm(n*multi, sd = sigmaep)

  return(data.frame(X, Y))
}

nw_simu <- function(data, testd, n, h, k){
  
    esti_nw <- testd$Y
    esti <- data.frame()
    X <- data$X
    Y <- data$Y
    real <- testd$Y
    test <- testd$X
    
    for(j in 1:length(test)){
    #set.seed(i) # random, may exist better solutions
        esti_nw[j] <- mhat(n,h,test[j],X,Y,k)
    }
    
    MSE_NW <- mean((real - esti_nw)^2)
    #browser()

    esti <- rbind(esti,data.frame(X = test,esti_nw))

  return(list(MSE = MSE_NW, esti = esti))
  
}

#Self-Supervised
ss_simu <- function(data, data_un, testd, n, h, m, g, k){
  esti <- data.frame()
    esti_ss <- testd$Y

    X <- data$X
    Y <- data$Y
    Xu <- data_un$X
    
    test <- testd$X
    real <- testd$Y
    
    for(j in 1:length(test)){
    #set.seed(i) # random, may exist better solutions
        esti_ss[j] <- rhat(n,h,test[j],X,Y,k,m,g,Xu)
    }
    
    MSE_SS <- mean((real - esti_ss)^2)
    #browser()

    esti <- rbind(esti,data.frame(X = test,esti_ss))
  
  
  return(list(MSE = MSE_SS, esti = esti))
  
}

hy_simu <- function(testd, lambda, esti_nw, esti_ss){
  
  esti <- data.frame()
  
  real <- testd$Y
  
  esti_hy <- lambda * esti_nw + (1-lambda) * esti_ss
  
  esti <- rbind(esti,data.frame(X = testd$X ,esti_hy))
  
  MSE_HY <- mean((real - esti_hy)^2)

  return(list(MSE = MSE_HY, esti = esti))
}
```

2. Experiment 1
Statistical setting: X ~ N(0, 1), epsilon ~ N(0, 1)
Model: Y = mx(x) + epsilon, mx(x) = x^2
Data: We have in total 128 * 2 data points of (X,Y). Then I choose n = 32, 64, 128, then split the data into training and testing data sets. Training data points are further split into labeled and unlabeled data. 

Set up hyperparameters, distribution functions and kernel
```{r}
sigmax <- 1
p <- function(x) 1/sqrt(2*pi*sigmax^2)*exp(-0.5*(x-0)^2/sigmax^2)
p_1 <- Deriv(p)
p_2 <- Deriv(p_1)
q <- function(x) 1/sqrt(2*pi*sigmax^2)*exp(-0.5*(x-0)^2/sigmax^2)
q_1 <- Deriv(q)
q_2 <- Deriv(q_1)
mx <- function(x) x^2
mx_1 <- Deriv(mx)
mx_2 <- Deriv(mx_1)

k <- function(x) 1/sqrt(2*pi)*exp(-0.5*(x-0)^2)
```

Suppose we know the true distribution of X 
```{r}
sigmak <- integrate(function(x) k(x)^2*x^2, -Inf, Inf)
rk <- integrate(function(x) k(x)^2, -Inf, Inf)
muk <- integrate(function(x) k(x)*x^2, -Inf, Inf)
#rp <- integrate(function(x) p_2(x)^2, -Inf, Inf)
#rq <- integrate(function(x) q_2(x)^2, -Inf, Inf)

theta22 <- integrate(function(x) mx_2(x)^2*p(x), -Inf, Inf)
sigmaep <- 1
```

There are some results helping us calculate the optimal h and g for NW estimator. But knowledge of true distribution and true mx() may be required. Since we are doing grid search, this won't make a difference but just for the sake of convenience. 
```{r}
paraset1 <- function(n, m_order, sigmaep, rk, muk, theta22){
  m <- round(n^m_order)
  h <- (rk/muk^2*sigmaep/(theta22*n))^(1/5)
  g <- (rk/muk^2*sigmaep/(theta22*m))^(1/5)
  
  lambda <- 1 + h^2/g^2
  return(data.frame(n,m,h,g,lambda))
}

paraset2 <- function(n, m_order, sigmaep, rk, muk, test){
  m <- round(n^m_order)
  h <- (rk/muk^2*sigmaep/(mx_2(2)^2*p(test)*n))^(1/5)
  g <- (rk/muk^2*sigmaep/(mx_2(2)^2*p(test)*m))^(1/5)
  
  lambda <- 1 + h^2/g^2
  return(data.frame(n,m,h,g,lambda))
}

paraset_g <- function(n, m_order,rk, muk){
  m <- round(n^m_order)
  h <- (rk/muk^2/(n))^(1/5)
  g <- (rk/muk^2/(m))^(1/5)
    
  lambda <- 1 + h^2/g^2
  return(data.frame(n,m,h,g,lambda))
}
```

Calculate parameter and test data point
```{r}
para <- paraset_g(128,10/19,rk$value, muk$value)
test <- data.frame(X = 1.5, Y = mx(1.5))
hlist <- seq(0.1,1,0.2)
glist <- seq(0.3,2.4,0.3)
epoch <- 10
rounds <- 20000
```

MSE for NW estimator
```{r}
set.seed(10)
hlist <- c(0.2)
record_nw <- matrix(nrow = length(hlist), ncol = epoch)

for(ep in 1:epoch){
  mMSE_NW <- 0
  
  for(r in 1:rounds){
  train_label <- simu_norm(para$n, 1, meanx = 0, sigmax = sigmax, sigmaep = sigmaep)
  train_un <- simu_norm(para$m, 1, meanx = 0, sigmax = sigmax, sigmaep = sigmaep)
  #test <- data[-sample,]
  #test <- data.frame(X = 2, Y = mx(2))
  result_nw <- data.frame()
  for(i in 1:length(hlist)){
    h <- hlist[i]
    MSE_NW <- nw_simu(train_label, test, para$n, h, k)$MSE
    
    result_nw <- rbind(result_nw, data.frame(mMSE_NW = MSE_NW, h))
  }
  mMSE_NW <- mMSE_NW + result_nw$mMSE_NW
  }
  result_nw$mMSE_NW <- mMSE_NW/rounds
  
  record_nw[,ep] <- result_nw$mMSE_NW
}


```

MSE for HY estimator
```{r}
set.seed(10)
hlist <- c(0.25)
glist <- c(0.9)

record_hy <- matrix(nrow = length(hlist)*length(glist), ncol = epoch)

for(ep in 1:epoch){
  mMSE_HY <- 0
  
  for(r in 1:rounds){
  train_label <- simu_norm(para$n, 1, meanx = 0, sigmax = sigmax, sigmaep = sigmaep)
  train_un <- simu_norm(para$m, 1, meanx = 0, sigmax = sigmax, sigmaep = sigmaep)
  
  result_hy <- data.frame()
  for(i in 1:length(hlist)){
    for(j in 1:length(glist)){
      h <- hlist[i]
      g <- glist[j]
      lambda <- 1 + h^2/g^2
      nw_res <- nw_simu(train_label, test, para$n, h, k)
      ss_res <- ss_simu(train_label, train_un, test, para$n,h, para$m,g, k)
      
      hy_res <- hy_simu(test, lambda, nw_res$esti$esti_nw, ss_res$esti$esti_ss)
      
      result_hy <- rbind(result_hy, data.frame(mMSE_HY = hy_res$MSE, h, g))
    }
  }
  mMSE_HY <- mMSE_HY + result_hy$mMSE_HY
  }

  result_hy$mMSE_HY <- mMSE_HY/rounds
  
  record_hy[,ep] <- result_hy$mMSE_HY
}

```

Calculate Monte Carlo Error
```{r}
MCM_nw <- apply(record_nw,1,mean)#MC mean
MCE_nw <- apply(record_nw,1,sd)#MC error
MC_nw <- data.frame(MCM = MCM_nw,MCE = MCE_nw,Lower = MCM_nw - MCE_nw,Upper = MCM_nw + MCE_nw)
MC_nw$h <- result_nw$h
```

```{r}
MCM_hy <- apply(record_hy,1,mean)
MCE_hy <- apply(record_hy,1,sd)
MC_hy <- data.frame(MCM = MCM_hy,MCE = MCE_hy,Lower = MCM_hy - MCE_hy,Upper = MCM_hy + MCE_hy)
MC_hy$h <- result_hy$h
MC_hy$g <- result_hy$g
```

Checking whether the mMSE have already converged
```{r}
hist(record_nw[NW_opt,])
mean(record_nw[NW_opt,])

hist(record_hy[HY_opt,])
mean(record_hy[HY_opt,],na.rm = T)

rolling_mean_nw <- record_nw
for (i in 2:ncol(record_nw)){
  rolling_mean_nw[,i] <- rowMeans(record_nw[,1:i])
}
plot(rolling_mean_nw[NW_opt,])
lines(rolling_mean_nw[2,])
lines(rolling_mean_nw[3,])
lines(rolling_mean_nw[4,])
lines(rolling_mean_nw[5,])

rolling_mean_hy <- record_hy
for (i in 2:ncol(record_hy)){
  rolling_mean_hy[,i] <- rowMeans(record_hy[,1:i])
}

plot(rolling_mean_hy[HY_opt,],pch = 3, cex = 0.5)
lines(rolling_mean_hy[26,])
```

Find the optimal h and g, and tuning the range of them
```{r}
min(MC_nw$MCM,na.rm = TRUE)
min(MC_hy$MCM,na.rm = TRUE)

NW_opt <- match(min(MC_nw$MCM,na.rm = TRUE),MC_nw$MCM)
HY_opt <-match(min(MC_hy$MCM,na.rm = TRUE),MC_hy$MCM)

plot(MCM~h,type = "b",data = MC_nw,col = "blue",main = str_c("h = ",MC_nw$h[NW_opt]))

g_main <- str_c("g = ",MC_hy$g[HY_opt])
h_main <- str_c("h = ",MC_hy$h[HY_opt])
plot(MCM~h,type = "b",data = filter(MC_hy, g == MC_hy$g[HY_opt]),main = g_main)
plot(MCM~g,type = "b",data = filter(MC_hy, h == MC_hy$h[HY_opt]),main = h_main)
```

Visualize the performance of estimators
```{r}
plot(MCM~h,data = filter(MC_hy, g == MC_hy$g[HY_opt]), type="b", pch=19, col="red", xlab="h", ylab="MSE",main = g_main)
# Add a line
lines(MCM~h,data = MC_nw, pch=18, col="blue", type="b", lty=2)
# Add a legend
legend("topright", legend=c("MSE_HY", "MSE_NW"),col=c("red", "blue"), lty=1:2, cex=0.8)
```

Visualize the performance of estimators: Two dimensional heatmap
```{r}
MC_hy$Group_by_percentile <- cut(MC_hy$MCM, breaks=c(quantile(MC_hy$MCM, probs = seq(0, 1, by = 0.20))),include.lowest = T)

heatmap1 <- ggplot(MC_hy, aes(h, g,fill = Group_by_percentile))
heatmap1 + geom_tile()+ 
  scale_fill_manual(breaks = levels(MC_hy$Group_by_percentile),
                    values = c("#86ebc9", "#869ceb",
                               "#b986eb","#a1eb86","#09855c"))+
  labs(title="Grid Search Result of MSE")+
  theme(plot.title = element_text(size=14,hjust = 0.5))
  
```

3. Confidence Interval
We need to estimate several unknown values in order to calculate the estimated variance.
First, we estimate derivative of mx(x) at x using mhat'(x).
```{r}
k_1 <- Deriv(k)

alpha_1 <- function(n, h, x, X, Y, k_1){
  temp <- sum(Y*k_1((x - X)/h)/(n*h^2))
  return(temp)
}

phat_1<- function(n, h, x, X, k_1){
  temp <- sum(k_1((x - X)/h)/(n*h^2))
  return(temp)
}

mhat_1 <- function(n, h, x, X, Y, k, k_1){
  return(alpha_1(n,h,x,X,Y,k_1)/phat(n,h,x,X,k) - alpha(n,h,x,X,Y,k)*phat_1(n,h,x,X,k_1)/phat(n,h,x,X,k)^2)
}
```

Here we write the function to estimate CI.
```{r}
esti_var <- function(n, h, m, g, mx_deriv1, sigmaep, px, qx, rk, sigmak, E_H_ratio = 1){
  var <- 1/(n*h*px)*sigmaep^2*rk + (h^4)/(m*g^3*qx)*E_H_ratio*mx_deriv1^2*sigmak
  return(var)
}

CI <- function(level,mx_deriv1,para,train_label,train_un,test,sigmaep_esti,px,qx,rk,sigmak,E_H_ratio = 1){
  var_esti <- esti_var(para$n,para$h,para$m,para$g,mx_deriv1,sigmaep_esti,px,qx,rk,sigmak,E_H_ratio = E_H_ratio)
  nw_esti <- mhat(para$n, para$h, test$X, train_label$X, train_label$Y, k)
  ss_esti <- rhat(para$n, para$h, test$X, train_label$X, train_label$Y, k, para$m, para$g, train_un$X)
  hy_esti <- hy_simu(test, para$lambda, nw_esti, ss_esti)$esti$esti_hy
  #browser()
  upper <- hy_esti + sqrt(var_esti)*qnorm(1-(1 - level)/2)
  lower <- hy_esti - sqrt(var_esti)*qnorm(1-(1 - level)/2)
  
  return(data.frame(n = para$n, h = para$h, g = para$g, lower, upper, esti = hy_esti, sd = sqrt(var_esti), length = (upper - lower), mx_1 = mx_deriv1))
}
```

Next, we estimate the error variance.
```{r}
esti_sigmaep <- function(n,h,train_label){
  esti <- train_label$Y
  for(i in 1:length(esti)){
    esti[i] <- mhat(n,h,x = train_label$X[i],X = train_label$X,Y = train_label$Y,k)
  }
  var_esti <- mean((esti - train_label$Y)^2)
  return(sqrt(var_esti))
}
```

Test how the variance estimator performs: Findings, the estimation works pretty well for the optimal (h,g)
```{r}
rounds <- 1

hlist <- seq(0.1,1,0.1)
glist <- seq(0.3,2,0.3)

mMSE_HY <- 0

set.seed(20)

for(exp in 1:rounds){
  data <- simu_norm(para$m + para$n, 1, meanx = 0, sigmax = sigmax, sigmaep = sigmaep)
    
  train_label <- data[1:para$n,]
  train_un <- data[(1+para$n):(para$m+para$n),]
  #test <- data[-sample,]
  #test <- data.frame(X = 2, Y = mx(2))
  
  var_esti <- data.frame()
  for(i in 1:length(hlist)){
    for(j in 1:length(glist)){
      h <- hlist[i]
      g <- glist[j]
      mx_deriv1 <- mhat_1(para$n,h,test$X,train_label$X,train_label$Y,k,k_1)
      px <- phat(para$n,h,test$X,train_label$X,k)
      qx <- phat(para$m,g,test$X,train_un$X,k)
      
      esti <- esti_var(para$n,h,para$m,g,mx_deriv1,sigmaep,px,qx,rk$value,sigmak$value,E_H_ratio = 1)
      var_esti <- rbind(var_esti, data.frame(mMSE_HY = esti, h, g, mx_1 = mx_deriv1))
    }
  }
  mMSE_HY <- mMSE_HY + var_esti$mMSE_HY
}

var_esti$mMSE_HY <- mMSE_HY/rounds
```

Experiment2: Then we can find the 95% level of h in 0.1 - 2 and g in 0.1 - 2, after setting the parameters. And subsequently find out their coverage probability.

Estimate the h that minimize mse, so as to approximate parameters using nw-estimator.
```{r}
nw_cv <- function(hlist = seq(0.1,4,0.1),train_label){
  mse_min <- 10000
  h_opt <- 0.1
  range <- quantile(train_label$X,c(0.05,0.95))
  for(h in hlist){
    mse <- 0
    
    for(exp in 1:nrow(train_label)){
        
        test <- train_label[exp,]
        if(test$X > range[1] && test$X < range[2]){
          train_label_loo <- train_label[-exp,]
          esti <- mhat(n = para$n,h = h,x = test$X,X = train_label_loo$X,Y = train_label_loo$Y,k)
          mse <- mse + (esti - test$Y)^2
        }
    }
    #print(mse)
    if(mse < mse_min){
      mse_min <- mse
      h_opt <- h
    }
  }
  return(h_opt)
}

nw_1_cv <- function(hlist = seq(0.1,1.4,0.1),train_label){
  mse_min <- 10000
  h_opt <- 0.1
  for(h in hlist){
    mse <- 0
    for(exp in 2:nrow(train_label)){
        
        test_x <- (train_label[exp-1,1]+train_label[exp,1])/2
        test_y <- (train_label[exp-1,2]-train_label[exp,2])/(train_label[exp-1,1]-train_label[exp,1])
        
        train_label_loo <- train_label[-((exp-1):exp),]
        
        esti <- mhat_1(n = para$n,h = h,x = test_x,X = train_label_loo$X,Y = train_label_loo$Y,k,k_1)
        
        mse <- mse + (esti - test_y)^2
        #print(test_y)
    }
    print(mse)
    if(mse < mse_min){
      mse_min <- mse
      h_opt <- h
    }
  }
  return(h_opt)
}
```

Estimate px, qx and m'(x)
```{r}
para$h <- (8*pi^(1/2)/3)^(1/5)*sd(data$X)*(rk$value/muk$value^2/para$n)^(1/5)
px <- phat(para$n,para$h,test$X,data$X,k)
qx <- px
h_opt <- nw_cv(hlist = seq(0.1,4,0.1),train_label)
mx_deriv1 <- mhat_1(para$n,h_opt,test$X,train_label$X,train_label$Y,k,k_1)
```

Estimate CI for all (h,g)
```{r}
hlist <- seq(0.1,1,0.1)
glist <- 1/(seq(1.1,0.2,-0.1))

CI <- data.frame()
for(i in hlist){
  para$h <- i
  for(j in glist){
    para$g <- j
    CI <- rbind(CI,CI_1(adjust = 1,0.95,para,train_label,train_un,test,sigmaep,rk$value,sigmak$value))
  }
}

plot(CI$esti, xlab = "Combinations", ylab = "Estimates", ylim = c(-10,10))
points(CI$lower, col = "red")
points(CI$upper, col = "blue")
abline(h = 4, col = "black")
legend("topright", legend=c("upper bound","lower bound"),col=c("blue","red"), pch = c(1,1),cex=0.8)
```

Draw the plot to show how CI performs GGPLOT2
```{r}
simulation <- 1:rounds
test_label <- str_c("n = ", para$n)
ggplot(data = coverage,aes(x = simulation,y = esti)) + 
  geom_line()+
  geom_hline(yintercept = test$Y)+
  geom_ribbon(aes(ymin=lower,ymax=upper),alpha=0.3)+
  labs(title="Plot of CI over 100 simulations",
        x =test_label, y = "Estimation")+
  theme(
plot.title = element_text(size=14,hjust = 0.5)
)

```

Diagnostics
```{r}
var(coverage$esti)
mean(coverage$sd)^2
```

Test the true coverage probability: sigmaep known
```{r}
hy_ci <- function(rounds,para,test,hlist,glist){
  coverage_byhg <- data.frame()

  for(h in hlist){
    for(g in glist){
      coverage <- data.frame()
      for(i in 1:rounds){
        data <- simu_norm(para$m + para$n, 1, meanx = 0, sigmax = sigmax, sigmaep = sigmaep)
      
        train_label <- data[1:para$n,]
        train_label <- arrange(train_label, X)
        train_un <- data[(1+para$n):(para$m+para$n),]
        
        h_opt <- (8*pi^(1/2)/3)^(1/5)*sd(data$X)*(rk$value/muk$value^2/para$n)^(1/5)
        px <- phat(para$n,h_opt,test$X,data$X,k)
        qx <- px
        #h_opt <- nw_1_cv(hlist = seq(0.1,2,0.1),train_label)
        h_opt <- nw_cv(hlist = seq(0.1,2,0.1),train_label)
        mx_deriv1 <- mhat_1(para$n,h_opt,test$X,train_label$X,train_label$Y,k,k_1)
        
        
        para$h <- h
        para$g <- g
        para$lambda <- 1 + h^2/g^2
        
        coverage <- rbind(coverage,CI(0.95,mx_deriv1,para,train_label,train_un,test,sigmaep_esti = sigmaep,px = px,qx = qx,rk$value,sigmak$value,E_H_ratio = 1))
      }
      coverage$cover <- (coverage$lower <= test$Y)*(coverage$upper >= test$Y)
        
      coverage_byhg <- rbind(coverage_byhg,data.frame(h = para$h, g  = para$g,length = mean(coverage$upper - coverage$lower), coverage = mean(coverage$cover,na.rm = T)))
    }
  }
  coverage_byhg$Error <- abs(coverage_byhg$coverage - 0.95)
return(coverage_byhg)
}
```

Test the true coverage probability: sigmaep unknown
```{r}
hy_ci_err <- function(rounds,para,test,hlist,glist){

  coverage_byhg <- data.frame()

  for(h in hlist){
    for(g in glist){
      coverage <- data.frame()
      for(i in 1:rounds){
  data <- simu_norm(para$m + para$n, 1, meanx = 0, sigmax = sigmax, sigmaep = sigmaep)

  train_label <- data[1:para$n,]
  train_label <- arrange(train_label, X)
  train_un <- data[(1+para$n):(para$m+para$n),]
  
  h_opt <- (8*pi^(1/2)/3)^(1/5)*sd(data$X)*(rk$value/muk$value^2/para$n)^(1/5)
  px <- phat(para$n,h_opt,test$X,data$X,k)
  qx <- px
  
  h_opt <- nw_cv(hlist = seq(0.1,4,0.1),train_label)
  sigmaep_esti <- esti_sigmaep(para$n,h_opt,train_label)
  
  #h_opt <- nw_1_cv(hlist = seq(0.1,2,0.1),train_label)
  mx_deriv1 <- mhat_1(para$n,h_opt,test$X,train_label$X,train_label$Y,k,k_1)
  
  para$h <- h
  para$g <- g
  para$lambda <- 1 + h^2/g^2
  
  coverage <- rbind(coverage,CI(0.95,mx_deriv1,para,train_label,train_un,test,sigmaep_esti = sigmaep_esti,px = px,qx = qx,rk$value,sigmak$value,E_H_ratio = 1))
}
      coverage$cover <- (coverage$lower <= test$Y)*(coverage$upper >= test$Y)
        
      coverage_byhg <- rbind(coverage_byhg,data.frame(h = para$h, g = para$g,length = mean(coverage$upper - coverage$lower), coverage = mean(coverage$cover,na.rm = T)))
    }
  }
  coverage_byhg$Error <- abs(coverage_byhg$coverage - 0.95)
return(coverage_byhg)
}
```

Test the true coverage probability: NW Estimator
```{r}

Bias_nw <- function(para, train_label, test_x, width, muk){
  pesti <- phat(para$n, para$h, test_x ,train_label$X, k)
  p1esti <- p_1_esti(para, train_label, test_x, width)
  mx1esti <- mx_1_esti(para, train_label, test_x, width)
  mx2esti <- mx_2_esti(para, train_label, test_x, width)
  bias <- para$h^2 * mx1esti  * p1esti * muk$value / pesti + para$h^2 * mx2esti * muk$value / 2
  return(bias)
}

Var_nw <- function(para, train_label, test_x, width, rk, sigmaep_esti){
  pesti <- phat(para$n, para$h, test_x ,train_label$X, k)
  return(sigmaep_esti^2*rk$value/(para$n*para$h*pesti))
}

CI_nw <- function(level,mx_deriv1,para,train_label,test,sigmaep_esti,px,rk,muk){
  var_esti <- Var_nw(para, train_label, test$X, width, rk, sigmaep_esti)
  bias_esti <- Bias_nw(para, train_label, test$X, width, muk)
  
  nw_esti <- mhat(para$n, para$h, test$X, train_label$X, train_label$Y, k)
  upper <- nw_esti - bias_esti + sqrt(var_esti)*qnorm(1-(1 - level)/2)
  lower <- nw_esti - bias_esti - sqrt(var_esti)*qnorm(1-(1 - level)/2)
  
  return(data.frame(n = para$n, h = para$h, g = para$g, lower, upper, esti = nw_esti, sd = sqrt(var_esti), length = (upper - lower), mx_1 = mx_deriv1))
}

nw_ci <- function(rounds,para, test, hlist){

    coverage_nw_byhg <- data.frame()
    
    for(h in hlist){
        coverage_nw <- data.frame()
        for(i in 1:rounds){
          data <- simu_norm(para$m + para$n, 1, meanx = 0, sigmax = sigmax, sigmaep = sigmaep)
          train_label <- data[1:para$n,]
          train_un <- data[(1+para$n):(para$n+para$m),]

          h_opt <- (8*pi^(1/2)/3)^(1/5)*sd(data$X)*(rk$value/muk$value^2/para$n)^(1/5)
          px <- phat(para$n,h_opt,test$X,data$X,k)

          h_opt <- nw_cv(hlist = seq(0.1,4,0.1),train_label)
          sigmaep_esti <- esti_sigmaep(para$n,h_opt,train_label)
          mx_deriv1 <- mhat_1(para$n,h_opt,test$X,train_label$X,train_label$Y,k,k_1)
  
          para$h <- h
  
          coverage_nw <- rbind(coverage_nw,CI_nw(0.95,mx_deriv1,para,train_label,test,sigmaep_esti,px,rk,muk))
        }
        
        coverage_nw$cover <- (coverage_nw$lower <= test$Y)*(coverage_nw$upper >= test$Y)
        
        coverage_nw_byhg <- rbind(coverage_nw_byhg,data.frame(h = h,length = mean(coverage_nw$upper - coverage_nw$lower), coverage = mean(coverage_nw$cover,na.rm = T)))
    }
    coverage_nw_byhg$Error <- abs(coverage_nw_byhg$coverage - 0.95)
  return(coverage_nw_byhg)
}
```

Use Bootstrap to estimate CI for NW-estimator and Test its coverage
```{r}
nw_boot_ci <- function(rounds,para, test, hlist){

    coverage_nw_byhg <- data.frame()
    
    for(h in hlist){
        coverage_nw <- data.frame()
        for(i in 1:rounds){
          data <- simu_norm(para$m + para$n, 1, meanx = 0, sigmax = sigmax, sigmaep = sigmaep)
          train_label <- data[1:para$n,]
          unlabeled <- data[(1+para$n):(para$n+para$m),]
          non_boot <- mhat(para$n,para$h,test$X,train_label$X,train_label$Y,k)
          
          h_opt <- (8*pi^(1/2)/3)^(1/5)*sd(data$X)*(rk$value/muk$value^2/para$n)^(1/5)
          px <- phat(para$n,h_opt,test$X,data$X,k)
          qx <- px

          h_opt <- nw_cv(hlist = seq(0.1,4,0.1),train_label)
          
          labeled <- nw_simu(data[1:para$n,],data[1:para$n,],para$n,h_opt,k)$esti
          names(labeled) <- c("X","Y")
          error <- data[1:para$n,]$Y - labeled$Y
          error <- error - mean(error)
          
          sigmaep_esti <- sd(error)
          
          #esti_nw <- mhat(para$n,para$h,test$X,data[1:para$n,]$X,data[1:para$n,]$Y,k)
          
          boot <- rep(0,1000)
          para$h <- h
          
          for(ep in 1:length(boot)){
            train_label <- labeled
            train_label$Y <- train_label$Y + error[sample(1:length(error), para$n,replace = T)]
            boot[ep] <- non_boot - mhat(para$n,para$h,test$X,train_label$X,train_label$Y,k)
          }
          boot_quan <- quantile(boot,c((1-0.95)/2,1-(1-0.95)/2)) + non_boot
          coverage_nw <- rbind(coverage_nw,data.frame(lower = boot_quan[1],upper = boot_quan[2]))
        }
        
        coverage_nw$cover <- (coverage_nw$lower <= test$Y)*(coverage_nw$upper >= test$Y)
        
        coverage_nw_byhg <- rbind(coverage_nw_byhg,data.frame(h = h,length = mean(coverage_nw$upper - coverage_nw$lower), coverage = mean(coverage_nw$cover,na.rm = T)))
    }
    coverage_nw_byhg$Error <- abs(coverage_nw_byhg$coverage - 0.95)
  return(coverage_nw_byhg)
}
```

Set parameter and (h,g) of interest
```{r}
para <- paraset_g(128,10/19,rk$value, muk$value)
test <- data.frame(X = 1.5, Y = mx(1.5))
hlist <- seq(0.05,1,0.05)
glist <- seq(0.3,2.4,0.3)
rounds <- 150
```

Find the relationship between bandwidth and coverage probability
```{r}
set.seed(20)

type <- 0
if(type == 0){
  #coverage_all <- nw_ci(rounds, para, test, hlist)
  coverage_all <- nw_boot_ci(rounds, para, test, hlist)
}else if(type == 1){
  coverage_all <- hy_ci(rounds, para, test, hlist, glist)
}else{
  coverage_all <- hy_ci_err(rounds, para, test, hlist, glist)
}
```

Visualize the relationship between (h, g) and coverage probability
```{r}
plot(glist,coverage_all$coverage[1:length(glist)],type = "n",pch = 1, ylab = "Coverage Probability", main = "(h,g) and Coverage Probability", ylim = c(0.3,1))
for(i in 1:length(hlist)){
  lines(glist,coverage_all$coverage[(1+(i-1)*length(glist)):(i*length(glist))], col = i, pch = i ,type = "b")
}
legend("bottomleft", legend = hlist,col=1:length(hlist), pch = 1:length(hlist), lty = 1,cex=0.8)
abline(h = 0.95, col = "black")
```

Visualize the performance of estimators: Two dimensional heatmap
```{r}
coverage_all$Error <- abs(coverage_all$coverage - 0.95)
#arrange(coverage_all,coverage_all$Error)[1:10,]
heatmap3 <- ggplot(coverage_all, aes(h, g, fill = Error))
heatmap3 + geom_tile()+
  labs(title="Grid Search Result of Coverage Error")+
  theme(plot.title = element_text(size = 14,hjust = 0.5))
```

Practical methods
Next I will propose 2 methods to choose the best (h,g) for coverage probability.

First generate sample.
```{r}
set.seed(30)
para <- paraset_g(32,10/19,rk$value, muk$value)
data <- simu_norm(para$n + para$m, 1, meanx = 0, sigmax = sigmax, sigmaep = sigmaep)
train_label <- data[1:para$n,]
train_un <- data[(1+para$n):(para$m+para$n),]
test <- data.frame(X = 1.5,Y = mx(1.5))
```

Find the best estimation of px, qx, m(x) and m'(x) in order to do bootstrap/estimate var(y_c_hat).
```{r}
para$h <- (8*pi^(1/2)/3)^(1/5)*sd(data$X)*(rk$value/muk$value^2/para$n)^(1/5)
px <- phat(para$n,para$h,test$X,data$X,k)
qx <- px

h_opt <- nw_cv(hlist = seq(0.1,4,0.1),train_label)
labeled <- nw_simu(data[1:para$n,],data[1:para$n,],para$n,h_opt,k)$esti
names(labeled) <- c("X","Y")
error <- labeled$Y - data[1:para$n,]$Y
error <- error - mean(error)
unlabeled <- data[(1+para$n):(para$n+para$m),]
sigmaep_esti <- sqrt(sd(error))
test_x <- 1
test <- data.frame(X = test_x, Y = mhat(n = para$n,h = h_opt,x = test_x,X = data[1:para$n,]$X,Y = data[1:para$n,]$Y,k))
mx_deriv1 <- mhat_1(para$n,h_opt,test$X,data[1:para$n,]$X,data[1:para$n,]$Y,k,k_1)
```

Take bias into consideration and estimate hg_opt
```{r}
# p_2 <- Deriv(p_1)
# p_3 <- Deriv(p_2)
# mx_2 <- Deriv(mx_1)
# mx_3 <- Deriv(mx_2)
# p_2 <- Deriv(p_1)
# p_3 <- Deriv(p_2)
# mx_2 <- Deriv(mx_1)
# mx_3 <- Deriv(mx_2)

p_1_esti <- function(para, train_label, test_x, width){
  esti <- (phat(para$n, para$h, test_x*(1 + width),train_label$X, k) - phat(para$n, para$h, test_x*(1 - width),train_label$X, k))/(test_x*2*width)
  return(esti)
}

p_2_esti <- function(para, train_label, test_x, width){
  esti <- (p_1_esti(para, train_label, test_x * (1 + width), width) - p_1_esti(para, train_label, test_x *(1 - width), width))/(test_x*2*width)
  return(esti)
}

p_3_esti <- function(para, train_label, test_x, width){
  esti <- (p_2_esti(para, train_label, test_x * (1 + width), width) - p_2_esti(para, train_label, test_x *(1 - width), width))/(test_x*2*width)
  return(esti)
}

mx_1_esti <- function(para, train_label, test_x, width){
  esti <- (mhat(para$n, para$h, test_x*(1 + width),train_label$X, train_label$Y, k) - mhat(para$n, para$h, test_x*(1 - width),train_label$X, train_label$Y, k))/(test_x*2*width)
  return(esti)
}

mx_2_esti <- function(para, train_label, test_x, width){
  esti <- (mx_1_esti(para, train_label, test_x * (1 + width), width) - mx_1_esti(para, train_label, test_x *(1 - width), width))/(test_x*2*width)
  return(esti)
}

mx_3_esti <- function(para, train_label, test_x, width){
  esti <- (mx_2_esti(para, train_label, test_x * (1 + width), width) - mx_2_esti(para, train_label, test_x *(1 - width), width))/(test_x*2*width)
  return(esti)
}

hg_optsearch <- function(para, train_label, test, width){
  test_x <- test$X
  pesti <- phat(para$n, para$h, test_x ,train_label$X, k)
  p1esti <- p_1_esti(para, train_label, test_x, width)
  p2esti <- p_2_esti(para, train_label, test_x, width)
  p3esti <- p_3_esti(para, train_label, test_x, width)
  
  mxesti <- mhat(para$n, para$h, test$X ,train_label$X, train_label$Y, k)
  mx1esti <- mx_1_esti(para, train_label, test_x, width)
  mx2esti <- mx_2_esti(para, train_label, test_x, width)
  mx3esti <- mx_3_esti(para, train_label, test_x, width)
  
  
  C1 <- (mx1esti*p3esti/pesti + mx2esti*p2esti/pesti + mx3esti*p1esti/pesti - p2esti*p1esti/pesti^2*mx1esti)/4
  C2 <- rk$value*sigmaep^2/pesti
  C3 <- sigmak$value * mx1esti^2/pesti
  
  mse <- function(hg){
  value <- (C1 * (hg[1]^4 - hg[1]^4*hg[2]^4))^2 + C2/(para$n * hg[1]) + C3 * hg[1]^4 /(para$m * hg[2]^2)
  return(value)
  }
  
  hgopt <- optim(c(0.1,0.5),mse)$par
  return(hgopt)
}
```

Exp3: After exploring the properties of the proposed estimator, we shall provide some methods to find the (h,g) can construct confidence interval. The first method is through the approximated variance.

Although from the equation, we observe that the variance is a decreasing function of g. But to ensure asymptotic properties holds and qhat is precise enough, g need to be small enough. We here choose it to be (8*pi^(1/2)/3)^(1/5)*sd(train_label$X)*(rk$value/muk$value^2/(para$m))^(1/5), which is approximated the best choice for "kernel density estimator". But this is very naive.
```{r}
h_opt_esti <- function(para,train_label,train_un,test,sigmaep_esti,rk,sigmak,E_H_ratio = 1){
  mx_deriv1 <- mhat_1(para$n,para$h,test$X,train_label$X,train_label$Y,k,k_1)
  h_opt <- (sigmaep_esti^2*rk$value/(4*mx_deriv1^2*sigmak$value))^(1/5)*(para$m*para$g^3)^(1/5)*para$n^(-1/5)
  return(h_opt)
}
```

Test the true coverage probability of proposed naive confidence interval
```{r}
set.seed(60)

rounds <- 200

para <- paraset_g(64,10/19,rk$value, muk$value)

coverage <- data.frame()

test <- data.frame(X = 1.5, Y = mx(1.5))

for(i in 1:rounds){
  data <- simu_norm(para$m + para$n, 1, meanx = 0, sigmax = sigmax, sigmaep = sigmaep)
  para <- paraset_g(para$n,10/19,rk$value, muk$value)
  train_label <- data[1:para$n,]
  train_un <- data[(1+para$n):(para$m+para$n),]
  
  h_opt <- (8*pi^(1/2)/3)^(1/5)*sd(data$X)*(rk$value/muk$value^2/para$n)^(1/5)
  px <- phat(para$n,h_opt,test$X,data$X,k)
  qx <- px
  
  h_opt <- nw_cv(hlist = seq(0.1,4,0.1),train_label)
  sigmaep_esti <- esti_sigmaep(para$n,h_opt,train_label)
  
  #h_opt <- nw_1_cv(hlist = seq(0.1,2,0.1),train_label)
  mx_deriv1 <- mhat_1(para$n,h_opt,test$X,train_label$X,train_label$Y,k,k_1)
  
  para$g <- (8*pi^(1/2)/3)^(1/5)*sd(train_label$X)*(rk$value/muk$value^2/para$m)^(1/5)
  para$h <- h_opt_esti(para,train_label,train_un,test,sigmaep_esti,rk,sigmak)
  para$lambda <- 1 + para$h^2/para$g^2
  
  coverage <- rbind(coverage,CI(0.95,mx_deriv1,para,train_label,train_un,test,sigmaep_esti = sigmaep_esti,px = px,qx = qx,rk$value,sigmak$value,E_H_ratio = 1))
}

coverage$cover <- (coverage$lower <= test$Y)*(coverage$upper >= test$Y)
mean(coverage$cover,na.rm = T)
```

Set parameters
```{r}
set.seed(30)
para <- paraset_g(2^8,10/19,rk$value, muk$value)
test <- data.frame(X = 1.5,Y = mx(1.5))
rounds <- 50
```

An alternative of naive CI is this
```{r}
set.seed(30)
coverage <- data.frame()
for(i in 1:rounds){
  data <- simu_norm(para$m + para$n, 1, meanx = 0, sigmax = sigmax, sigmaep = sigmaep)

  train_label <- data[1:para$n,]
  #train_label <- arrange(train_label, X)
  train_un <- data[(1+para$n):(para$m+para$n),]
  
  h_opt <- (8*pi^(1/2)/3)^(1/5)*sd(data$X)*(rk$value/muk$value^2/para$n)^(1/5)
  px <- phat(para$n,h_opt,test$X,data$X,k)
  qx <- px
  
  h_opt <- nw_cv(hlist = seq(0.1,2,0.1),train_label)
  sigmaep_esti <- esti_sigmaep(para$n,h_opt,train_label)
  
  #h_opt <- nw_1_cv(hlist = seq(0.1,2,0.1),train_label)
  mx_deriv1 <- mhat_1(para$n,h_opt,test$X,train_label$X,train_label$Y,k,k_1)
  #mx_deriv1 <- 3
  
  hg_opt <- hg_optsearch(para, train_label, test, width = 0.01)
  
  para$h <- hg_opt[1]
  #para$h <- h_opt
  para$g <- hg_opt[2]
  para$lambda <- 1 + para$h^2/para$g^2
  
  coverage <- rbind(coverage,CI(0.95,mx_deriv1,para,train_label,train_un,test,sigmaep_esti = sigmaep_esti,px = px,qx = qx,rk$value,sigmak$value,E_H_ratio = 1))
}
      coverage$cover <- (coverage$lower <= test$Y)*(coverage$upper >= test$Y)
      mean(coverage$cover)
```

GGPLOT2: From the plots, we can see that the choice of g is quite large. I suspect that this is because of the large variance of g. I will now change sigmax to 1. The finding is interesting, coverage probability now is increasing with n and m. 
```{r}
simulation <- 1:rounds
test_label <- str_c("n = ", para$n)
ggplot(data = coverage,aes(x = simulation,y = esti)) + 
  geom_line()+
  geom_hline(yintercept = test$Y)+
  geom_ribbon(aes(ymin=lower,ymax=upper),alpha=0.3)+
  labs(title="Plot of CI over 100 simulations",
        x =test_label, y = "Estimation")+
  theme(
plot.title = element_text(size=14,hjust = 0.5)
)
```

Exp4: After exploring the properties of the proposed estimator, we shall provide some methods to find the (h,g) can construct confidence interval. The second method is through resampling and cross-validation.

Secondly, prepare for bootstrap.

Testing Bootstrap
```{r}
train_label <- labeled[sample(1:nrow(labeled), para$n,replace = T),]
train_un <- unlabeled[sample(1:nrow(unlabeled), para$m,replace = T),]
train_label$Y <- train_label$Y + error[sample(1:length(error), para$n,replace = T)]
esti <- nw_simu(train_label,train_label,para$n,para$h,k)$esti
plot(train_label$X,train_label$Y)
points(data$X,data$X^2,col = "red")
points(esti$X,esti$esti_nw,col = "blue")
```

Select the (h,g) with best coverage: Bootstrap
```{r}
hlist <- seq(0.1,1,0.1)
glist <- seq(0.3,3,0.3)

rounds <- 500

coverage <- data.frame()
result_ci <- data.frame()

for(i in 1:length(hlist)){
  for(j in 1:length(glist)){
      coverage <- data.frame()
      set.seed(10)
    for(exp in 1:rounds){

      train_label <- labeled
      train_label$Y <- train_label$Y + error[sample(1:length(error), para$n,replace = T)]
      
      para$h <- hlist[i]
      para$g <- glist[j]
      
      coverage <- rbind(coverage,CI(0.95,mx_deriv1,para,train_label,train_un,test,px,qx,sigmaep_esti,rk$value,sigmak$value))
    }
    cover <- (coverage$lower <= test$Y)*(coverage$upper >= test$Y)
    
    cover_prop <- mean(cover,na.rm = T)
      
    result_ci <- rbind(result_ci, data.frame(h = para$h, g = para$g, cover_prop, sd = sqrt(mean(coverage$sd^2))))
  }
}
result_ci$error <- abs(result_ci$cover_prop - 0.95)
```

Select the (h,g) with best coverage: leave one out cross validation. There is one huge drawback of this method. It does not take into consideration the mse or accuracy of length of CI. 
```{r}
loocv <- function(para,hlist, glist, train_label, train_un){

  result_ci <- data.frame()

  for(i in 1:length(hlist)){
  for(j in 1:length(glist)){
      coverage <- data.frame()
      para$h <- hlist[i]
      para$g <- glist[j]
      sigmaep_esti <- esti_sigmaep(para$n,para$h,train_label)
    for(exp in 1:nrow(train_label)){
      
      test <- train_label[exp,]
      
      train_label_loo <- train_label[-exp,]
      
      coverage <- rbind(coverage,CI(0.95,mx_deriv1,para,train_label,train_un,test,px,qx,sigmaep_esti,rk$value,sigmak$value))
    }
    coverage <- cbind(coverage, train_label)
    cover <- (coverage$lower <= train_label$Y)*(coverage$upper >= train_label$Y)
    
    cover_prop <- mean(cover,na.rm = T)
    
    result_ci <- rbind(result_ci, data.frame(h = para$h, g = para$g, cover_prop, msd = sqrt(mean(coverage$sd^2))))
  }
  }
  result_ci$error <- abs(result_ci$cover_prop - 0.95)
  
  best <- result_ci[match(min(result_ci$error),result_ci$error),]
  
  return(best)
}

```

Test the true coverage of the chosen (h,g) according to loocv
```{r}
set.seed(60)

rounds <- 100

para <- paraset_g(64,10/19,rk$value, muk$value)
test <- data.frame(X = 1.5, Y = mx(1.5))

hlist <- seq(0.1,1,0.1)
glist <- seq(0.3,3,0.3)

coverage_exp4 <- data.frame()

for(i in 1:rounds){
  data <- simu_norm(para$m + para$n, 1, meanx = 0, sigmax = sigmax, sigmaep = sigmaep)
  train_label <- data[1:para$n,]
  train_un <- data[(1+para$n):(para$m+para$n),]
  
  h_opt <- nw_cv(hlist = seq(0.1,2,0.1),train_label)
  sigmaep_esti <- esti_sigmaep(para$n,h_opt,train_label)
  
  #h_opt <- nw_1_cv(hlist = seq(0.1,2,0.1),train_label)
  mx_deriv1 <- mhat_1(para$n,h_opt,test$X,train_label$X,train_label$Y,k,k_1)
  
  best <- loocv(para,hlist,glist,train_label,train_un)
  
  para$h <- best$h
  
  para$g <- best$g
  
  coverage_exp4 <- rbind(coverage_exp4,CI(0.95,mx_deriv1,para,train_label,train_un,test,px,qx,sigmaep_esti,rk$value,sigmak$value))
}

coverage_exp4$cover <- (coverage_exp4$lower <= test$Y)*(coverage_exp4$upper >= test$Y)
mean(coverage_exp4$cover,na.rm = T)
```

Test the true coverage of the chosen (h,g) according to loocv
```{r}
set.seed(60)

rounds <- 100

para <- paraset_g(64,10/19,rk$value, muk$value)
test <- data.frame(X = 1.5, Y = mx(1.5))

h <- c(1)
g <- seq(0.3,0.3,0.3)

coverage <- data.frame()

for(i in 1:rounds){
  data <- simu_norm(para$m + para$n, 1, meanx = 0, sigmax = sigmax, sigmaep = sigmaep)
  train_label <- data[1:para$n,]
  train_un <- data[(1+para$n):(para$m+para$n),]
  
  h_opt <- nw_cv(hlist = seq(0.1,2,0.1),train_label)
  sigmaep_esti <- esti_sigmaep(para$n,h_opt,train_label)
  
  #h_opt <- nw_1_cv(hlist = seq(0.1,2,0.1),train_label)
  mx_deriv1 <- mhat_1(para$n,h_opt,test$X,train_label$X,train_label$Y,k,k_1)
  
  para$h <- h
  
  para$g <- g
  
  coverage <- rbind(coverage,CI(0.95,mx_deriv1,para,train_label,train_un,test,px,qx,sigmaep_esti,rk$value,sigmak$value))
}

coverage$cover <- (coverage$lower <= test$Y)*(coverage$upper >= test$Y)
mean(coverage$cover,na.rm = T)
```

Draw the plot to show how CI performs GGPLOT2
```{r}
simulation <- 1:rounds
test_label <- str_c("n = ", para$n)
ggplot(data = coverage,aes(x = simulation,y = esti)) + 
  geom_line()+
  geom_hline(yintercept = test$Y)+
  geom_ribbon(aes(ymin=lower,ymax=upper),alpha=0.3)+ 
  labs(y = "m(x)")
#+labs(title="Plot of CI over 100 simulations",x =test_label, y = #"Estimation")+
  #theme(plot.title = element_text(size=14,hjust = 0.5))
```

avoid setting h too small when the data is sparse. Redefine phat so not fall below the constant.
Common approach to avoid Computational issue

Possible Conclusion: the choice of h and g matters and our choice should depend on our goal, i.e., whether we want better confidence interval or smaller mse.