---
title: "Stat3799 Simulation"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(Deriv)
library(ggplot2)
library(hrbrthemes)
```

1. General Setup and Testing

```{r}
alpha <- function(n, h, x, X, Y, k){
  temp <- 0
  for(i in 1:length(X)){
    temp <- temp + Y[i] * k((x - X[i])/h)/(n*h)
  }
  return(temp)
}

valpha <- Vectorize(alpha,SIMPLIFY = FALSE)

phat<- function(n, h, x, X, k){
  temp <- sum(k((x - X)/h)/(n*h))
  return(max(temp,0.001)) #this is to prevent the estimation from resulting in NA
}

vphat<- Vectorize(phat)

mhat <- function(n, h, x, X, Y, k){
  return(alpha(n,h,x,X,Y,k)/phat(n,h,x,X,k))
}

vmhat <- function(n, h, x, X, Y, k){
  return(valpha(n,h,x,X,Y,k)/vphat(n,h,x,X,k))
}

beta <- function(n, h, x, X, Y, k, m, g, Xu){
  Yu <- 1:length(Xu)
  for(i in 1:length(Xu)){
    Yu[i] <- mhat(n, h, Xu[i], X, Y, k)
  }
  return(alpha(m,g,x,Xu,Yu,k))
}

rhat <- function(n, h, x, X, Y, k, m, g, Xu){
  return(beta(n, h, x, X, Y, k, m, g, Xu)/phat(m,g,x,Xu,k))
}
```

Simulation functions
```{r}
simu_unif <- function(multi, n, xmax, sigmaep = 1){

    X <- runif(n*multi,xmax)
    Y <- mx(X) + rnorm(n*multi, sd = sigmaep)

  return(data.frame(X, Y))
}

simu_norm <- function(multi, n, meanx, sigmax, sigmaep = 1){

    X <- rnorm(n*multi,mean = meanx,sd = sigmax)
    Y <- mx(X) + rnorm(n*multi, sd = sigmaep)

  return(data.frame(X, Y))
}

nw_simu <- function(data, testd, n, h, k){
  
    esti_nw <- testd$Y
    esti <- data.frame()
    X <- data$X
    Y <- data$Y
    real <- testd$Y
    test <- testd$X
    
    for(j in 1:length(test)){
    #set.seed(i) # random, may exist better solutions
        esti_nw[j] <- mhat(n,h,test[j],X,Y,k)
    }
    
    MSE_NW <- mean((real - esti_nw)^2)
    #browser()

    esti <- rbind(esti,data.frame(X = test,esti_nw))

  return(list(MSE = MSE_NW, esti = esti))
  
}

#Self-Supervised
ss_simu <- function(data, data_un, testd, n, h, m, g, k){
  esti <- data.frame()
    esti_ss <- testd$Y

    X <- data$X
    Y <- data$Y
    Xu <- data_un$X
    
    test <- testd$X
    real <- testd$Y
    
    for(j in 1:length(test)){
    #set.seed(i) # random, may exist better solutions
        esti_ss[j] <- rhat(n,h,test[j],X,Y,k,m,g,Xu)
    }
    
    MSE_SS <- mean((real - esti_ss)^2)
    #browser()

    esti <- rbind(esti,data.frame(X = test,esti_ss))
  
  
  return(list(MSE = MSE_SS, esti = esti))
  
}

hy_simu <- function(testd, lambda, esti_nw, esti_ss){
  
  esti <- data.frame()
  
  real <- testd$Y
  
  esti_hy <- lambda * esti_nw + (1-lambda) * esti_ss
  
  esti <- rbind(esti,data.frame(X = testd$X ,esti_hy))
  
  MSE_HY <- mean((real - esti_hy)^2)

  return(list(MSE = MSE_HY, esti = esti))
}
```

2. Experiment 1
Statistical setting: X ~ N(0, 1), epsilon ~ N(0, 1)
Model: Y = mx(x) + epsilon, mx(x) = x^2
Data: We have in total 128 * 2 data points of (X,Y). Then I choose n = 32, 64, 128, then split the data into training and testing data sets. Training data points are further split into labeled and unlabeled data. 

Set up hyperparameters, distribution functions and kernel
```{r}
sigmax <- 1
p <- function(x) 1/sqrt(2*pi*sigmax^2)*exp(-0.5*(x-0)^2/sigmax^2)
p_1 <- Deriv(p)
p_2 <- Deriv(p_1)
q <- function(x) 1/sqrt(2*pi*sigmax^2)*exp(-0.5*(x-0)^2/sigmax^2)
q_1 <- Deriv(q)
q_2 <- Deriv(q_1)
mx <- function(x) x^2
mx_1 <- Deriv(mx)
mx_2 <- Deriv(mx_1)

k <- function(x) 1/sqrt(2*pi)*exp(-0.5*(x-0)^2)
```

Suppose we know the true distribution of X 
```{r}
sigmak <- integrate(function(x) k(x)^2*x^2, -Inf, Inf)
rk <- integrate(function(x) k(x)^2, -Inf, Inf)
muk <- integrate(function(x) k(x)*x^2, -Inf, Inf)
#rp <- integrate(function(x) p_2(x)^2, -Inf, Inf)
#rq <- integrate(function(x) q_2(x)^2, -Inf, Inf)

theta22 <- integrate(function(x) mx_2(x)^2*p(x), -Inf, Inf)
sigmaep <- 1
```

There are some results helping us calculate the optimal h and g for NW estimator. But knowledge of true distribution and true mx() may be required. Since we are doing grid search, this won't make a difference but just for the sake of convenience. 
```{r}
paraset1 <- function(n, m_order, sigmaep, rk, muk, theta22){
  m <- round(n^m_order)
  h <- (rk/muk^2*sigmaep/(theta22*n))^(1/5)
  g <- (rk/muk^2*sigmaep/(theta22*m))^(1/5)
  
  lambda <- 1 + h^2/g^2
  return(data.frame(n,m,h,g,lambda))
}

paraset2 <- function(n, m_order, sigmaep, rk, muk, test){
  m <- round(n^m_order)
  h <- (rk/muk^2*sigmaep/(mx_2(2)^2*p(test)*n))^(1/5)
  g <- (rk/muk^2*sigmaep/(mx_2(2)^2*p(test)*m))^(1/5)
  
  lambda <- 1 + h^2/g^2
  return(data.frame(n,m,h,g,lambda))
}

paraset_g <- function(n, m_order,rk, muk){
  m <- round(n^m_order)
  h <- (rk/muk^2/(n))^(1/5)
  g <- (rk/muk^2/(m))^(1/5)
    
  lambda <- 1 + h^2/g^2
  return(data.frame(n,m,h,g,lambda))
}
```

Calculate parameter and test data point
```{r}
para <- paraset_g(32,10/19,rk$value, muk$value)
test <- data.frame(X = 2, Y = mx(2))
```

Do simulations to find the (h,g) with smallest MSE: Resampling. This is errorneous
```{r}
set.seed(50)

data <- simu_norm(para$n + para$m, 1, meanx = 0, sigmax = sigmax, sigmaep = sigmaep)
labeled <- nw_simu(data[1:para$n,],data,para$n,para$h,k)$esti
names(labeled) <- c("X","Y")
unlabeled <- data
error <- labeled$Y - data$Y

rounds <- 100

hlist <- seq(0.1,1,0.1)
glist <- seq(0.3,2,0.3)

mMSE_NW <- 0
mMSE_HY <- 0

set.seed(43)
record_nw <- matrix(nrow = length(hlist), ncol = rounds)#
record_hy <- matrix(nrow = length(hlist)*length(glist), ncol = rounds)#

for(exp in 1:rounds){
  
  # sample <- sample.int(n = nrow(data), size = para$n, replace = T)
  # train_label <- data[sample,]
  # sample <- sample.int(n = nrow(data), size = para$m, replace = T)
  # train_un <- data[sample,]
  #test <- data[-sample,]
  train_label <- labeled[sample(1:nrow(labeled), para$n,replace = T),]
  train_un <- unlabeled[sample(1:nrow(unlabeled), para$m,replace = T),]
  train_label$Y <- train_label$Y + error[sample(1:length(error), para$n,replace = T)]
  
  result_nw <- data.frame()
  for(i in 1:length(hlist)){
    #h <- hlist[i]*para$h
    h <- hlist[i]
    MSE_NW <- nw_simu(train_label, test, para$n,h, k)$MSE
    
    result_nw <- rbind(result_nw, data.frame(mMSE_NW = MSE_NW, h))
  }
  record_nw[,exp] <- result_nw$mMSE_NW #
  mMSE_NW <- mMSE_NW + result_nw$mMSE_NW
  
  result_hy <- data.frame()
  for(i in 1:length(hlist)){
    for(j in 1:length(glist)){
      h <- hlist[i]
      g <- glist[j]
      para$lambda <- 1 + h^2/g^2
      nw_res <- nw_simu(train_label, test, para$n,h, k)
      ss_res <- ss_simu(train_label, train_un, test, para$n,h, para$m,g, k)
      
      hy_res <- hy_simu(test, para$lambda, nw_res$esti$esti_nw, ss_res$esti$esti_ss)
      
      result_hy <- rbind(result_hy, data.frame(mMSE_HY = hy_res$MSE, h, g))
    }
  }
  record_hy[,exp] <- result_hy$mMSE_HY#
  mMSE_HY <- mMSE_HY + result_hy$mMSE_HY
}

result_nw$mMSE_NW <- mMSE_NW/rounds
result_hy$mMSE_HY <- mMSE_HY/rounds
```

Do simulations: True repitition
```{r}
rounds <- 100

hlist <- seq(0.1,1,0.1)
glist <- seq(0.3,3,0.3)

mMSE_NW <- 0
mMSE_HY <- 0

set.seed(10)
record_nw <- matrix(nrow = length(hlist), ncol = rounds)
record_hy <- matrix(nrow = length(hlist)*length(glist), ncol = rounds)

for(exp in 1:rounds){
  data <- simu_norm(para$m + para$n, 1, meanx = 0, sigmax = sigmax, sigmaep = sigmaep)
    
  train_label <- data[1:para$n,]
  train_un <- data[(1+para$n):(para$m+para$n),]
  #test <- data[-sample,]
  #test <- data.frame(X = 2, Y = mx(2))
  result_nw <- data.frame()
  for(i in 1:length(hlist)){
    h <- hlist[i]
    MSE_NW <- nw_simu(train_label, test, para$n,h, k)$MSE
    
    result_nw <- rbind(result_nw, data.frame(mMSE_NW = MSE_NW, h))
  }
  record_nw[,exp] <- result_nw$mMSE_NW #
  mMSE_NW <- mMSE_NW + result_nw$mMSE_NW
  
  result_hy <- data.frame()
  for(i in 1:length(hlist)){
    for(j in 1:length(glist)){
      h <- hlist[i]
      g <- glist[j]
      para$lambda <- 1 + h^2/g^2
      nw_res <- nw_simu(train_label, test, para$n,h, k)
      ss_res <- ss_simu(train_label, train_un, test, para$n,h, para$m,g, k)
      
      hy_res <- hy_simu(test, para$lambda, nw_res$esti$esti_nw, ss_res$esti$esti_ss)
      
      result_hy <- rbind(result_hy, data.frame(mMSE_HY = hy_res$MSE, h, g))
    }
  }
  record_hy[,exp] <- result_hy$mMSE_HY
  mMSE_HY <- mMSE_HY + result_hy$mMSE_HY
}

result_nw$mMSE_NW <- mMSE_NW/rounds
result_hy$mMSE_HY <- mMSE_HY/rounds
```

Checking whether the mMSE have already converged
```{r}
hist(record_nw[NW_opt,])
mean(record_nw[NW_opt,])

hist(record_hy[HY_opt,])
mean(record_hy[HY_opt,],na.rm = T)

rolling_mean_nw <- record_nw
for (i in 2:ncol(record_nw)){
  rolling_mean_nw[,i] <- rowMeans(record_nw[,1:i])
}
plot(rolling_mean_nw[NW_opt,])
lines(rolling_mean_nw[2,])
lines(rolling_mean_nw[3,])
lines(rolling_mean_nw[4,])
lines(rolling_mean_nw[5,])

rolling_mean_hy <- record_hy
for (i in 2:ncol(record_hy)){
  rolling_mean_hy[,i] <- rowMeans(record_hy[,1:i])
}

plot(rolling_mean_hy[HY_opt,],pch = 3, cex = 0.5)
lines(rolling_mean_hy[26,])
```

Find the optimal h and g, and tuning the range of them
```{r}
min(result_nw$mMSE_NW,na.rm = TRUE)
min(result_hy$mMSE_HY,na.rm = TRUE)

NW_opt <- match(min(result_nw$mMSE_NW,na.rm = TRUE),result_nw$mMSE_NW)
HY_opt <-match(min(result_hy$mMSE_HY,na.rm = TRUE),result_hy$mMSE_HY)

plot(mMSE_NW~h,data = result_nw,col = "blue",main = str_c("h = ",result_nw$h[NW_opt]))

g_main <- str_c("g = ",result_hy$g[HY_opt])
h_main <- str_c("h = ",result_hy$h[HY_opt])
plot(mMSE_HY~h,type = "b",data = filter(result_hy, g == result_hy$g[HY_opt]),main = g_main)
plot(mMSE_HY~g,type = "b",data = filter(result_hy, h == result_hy$h[HY_opt]),main = h_main)
```

Visualize the performance of estimators
```{r}
plot(mMSE_HY~h,data = filter(result_hy, g == result_hy$g[HY_opt]), type="b", pch=19, col="red", xlab="h", ylab="MSE",main = g_main)
# Add a line
lines(mMSE_NW~h,data = result_nw, pch=18, col="blue", type="b", lty=2)
# Add a legend
legend("topright", legend=c("MSE_HY", "MSE_NW"),col=c("red", "blue"), lty=1:2, cex=0.8)
```

Visualize the performance of estimators: Two dimensional heatmap
```{r}
result_hy$Group_by_percentile <- cut(result_hy$mMSE_HY, breaks=c(quantile(result_hy$mMSE_HY, probs = seq(0, 1, by = 0.20))),include.lowest = T)

heatmap1 <- ggplot(result_hy, aes(h, g,fill = Group_by_percentile))
heatmap1 + geom_tile()+ 
  scale_fill_manual(breaks = levels(result_hy$Group_by_percentile),
                    values = c("#86ebc9", "#869ceb",
                               "#b986eb","#a1eb86","#09855c"))+
  labs(title="Grid Search Result of MSE")+
  theme(plot.title = element_text(size=14,hjust = 0.5))
  
```

3. Confidence Interval
We need to estimate several unknown values in order to calculate the estimated variance.
First, we estimate derivative of mx(x) at x using mhat'(x).
```{r}
k_1 <- Deriv(k)

alpha_1 <- function(n, h, x, X, Y, k_1){
  temp <- sum(Y*k_1((x - X)/h)/(n*h^2))
  return(temp)
}

phat_1<- function(n, h, x, X, k_1){
  temp <- sum(k_1((x - X)/h)/(n*h^2))
  return(temp)
}

mhat_1 <- function(n, h, x, X, Y, k, k_1){
  return(alpha_1(n,h,x,X,Y,k_1)/phat(n,h,x,X,k) - alpha(n,h,x,X,Y,k)*phat_1(n,h,x,X,k_1)/phat(n,h,x,X,k)^2)
}

```

For the time being, we assume the error variance is known to us and do some simulations.
```{r}
esti_var <- function(n, h, m, g, mx_deriv1, sigmaep, px, qx, rk, sigmak, E_H_ratio = 1){
  var <- 1/(n*h*px)*sigmaep^2*rk + (h^4)/(m*g^3*qx)*E_H_ratio*mx_deriv1^2*sigmak
  return(var)
}

CI <- function(level,mx_deriv1,para,train_label,train_un,test,sigmaep_esti,px,qx,rk,sigmak,E_H_ratio = 1){
  n <- para$n
  h <- para$h
  m <- para$m
  g <- para$g
  X <- train_label$X
  Y <- train_label$Y
  
  var_esti <- esti_var(n,h,m,g,mx_deriv1,sigmaep,px,qx,rk,sigmak,E_H_ratio = E_H_ratio)
  para$lambda <- 1 + h^2/g^2
  nw_esti <- mhat(n, h, test$X, X, Y, k)
  ss_esti <- rhat(n, h, test$X, X, Y, k, m, g, train_un$X)
  hy_esti <- hy_simu(test, para$lambda, nw_esti, ss_esti)$esti$esti_hy
  #browser()
  upper <- hy_esti + sqrt(var_esti)*qnorm(1-(1 - level)/2)
  lower <- hy_esti - sqrt(var_esti)*qnorm(1-(1 - level)/2)
  
  return(data.frame(n = n, h = h, g = g, lower, upper, esti = hy_esti, sd = sqrt(var_esti)))
}
```

Test how the variance estimator performs: Findings, the estimation works pretty well for the optimal (h,g)
```{r}
rounds <- 1

hlist <- seq(0.1,1,0.1)
glist <- seq(0.3,2,0.3)

mMSE_HY <- 0

set.seed(20)

for(exp in 1:rounds){
  data <- simu_norm(para$m + para$n, 1, meanx = 0, sigmax = sigmax, sigmaep = sigmaep)
    
  train_label <- data[1:para$n,]
  train_un <- data[(1+para$n):(para$m+para$n),]
  #test <- data[-sample,]
  #test <- data.frame(X = 2, Y = mx(2))
  
  var_esti <- data.frame()
  for(i in 1:length(hlist)){
    for(j in 1:length(glist)){
      h <- hlist[i]
      g <- glist[j]
      mx_deriv1 <- mhat_1(para$n,h,test$X,train_label$X,train_label$Y,k,k_1)
      px <- phat(para$n,h,test$X,train_label$X,k)
      qx <- phat(para$m,g,test$X,train_un$X,k)
      
      esti <- esti_var(para$n,h,para$m,g,mx_deriv1,sigmaep,px,qx,rk$value,sigmak$value,E_H_ratio = 1)
      var_esti <- rbind(var_esti, data.frame(mMSE_HY = esti, h, g, mx_1 = mx_deriv1))
    }
  }
  mMSE_HY <- mMSE_HY + var_esti$mMSE_HY
}

var_esti$mMSE_HY <- mMSE_HY/rounds
```

Experiment2: Then we can find the 95% level of h in 0.1 - 2 and g in 0.1 - 2, after setting the parameters. And subsequently find out their coverage probability.

Setup parameters and sample.
```{r}
para <- paraset_g(32,10/19,rk$value, muk$value)
```

```{r}
set.seed(20)
data <- simu_norm(para$m + para$n, 1, para$m, meanx = 0, sigmax = sigmax, sigmaep = sigmaep)
train_label <- data[1:para$n,]
train_un <- data[(1+para$n):(para$m+para$n),]
```

```{r}
#Estimate px and qx
para$h <- (8*pi^(1/2)/3)^(1/5)*sd(data$X)*(rk$value/muk$value^2/para$n)^(1/5)
px <- phat(para$n,para$h,test$X,data$X,k)
qx <- px

mx_deriv1 <- mhat_1(n,h,test$X,X,Y,k,k_1)
```

Estimate CI for all (h,g)
```{r}
hlist <- seq(0.1,1,0.1)
glist <- 1/(seq(1.1,0.2,-0.1))

CI <- data.frame()
for(i in hlist){
  para$h <- i
  for(j in glist){
    para$g <- j
    CI <- rbind(CI,CI_1(adjust = 1,0.95,para,train_label,train_un,test,sigmaep,rk$value,sigmak$value))
  }
}

plot(CI$esti, xlab = "Combinations", ylab = "Estimates", ylim = c(-10,10))
points(CI$lower, col = "red")
points(CI$upper, col = "blue")
abline(h = 4, col = "black")
legend("topright", legend=c("upper bound","lower bound"),col=c("blue","red"), pch = c(1,1),cex=0.8)
```

Test the true coverage probability
```{r}
set.seed(10)

rounds <- 100

para$h <- 0.8 #result_hy$h[HY_opt]
para$g <- 0.6 # result_hy$g[HY_opt]

coverage <- data.frame()

for(i in 1:rounds){
  data <- simu_norm(para$m + para$n, 1, meanx = 0, sigmax = sigmax, sigmaep = sigmaep)

  train_label <- data[1:para$n,]
  train_un <- data[(1+para$n):(para$m+para$n),]
  
  coverage <- rbind(coverage,CI(0.95,mx_deriv1,para,train_label,train_un,test,px,qx,sigmaep,rk$value,sigmak$value))
}

coverage$cover <- (coverage$lower <= test$Y)*(coverage$upper >= test$Y)
mean(coverage$cover,na.rm = T)

```

Draw the plot to show how CI performs
```{r}
plot(coverage$lower, xlab = "Combinations", ylab = "Estimates",col="red", ylim = c(0,10))
points(coverage$upper, col = "blue")
lines(coverage$esti, lty = 2)
abline(h = 4, col = "black")
legend("topright", legend=c("upper bound","lower bound"),col=c("blue","red"), pch = c(1,1),cex=0.8)
```

GGPLOT2
```{r}
simulation <- 1:rounds
test_label <- str_c("n = ", para$n)
ggplot(data = coverage,aes(x = simulation,y = esti)) + 
  geom_line()+
  geom_hline(yintercept = test$Y)+
  geom_ribbon(aes(ymin=lower,ymax=upper),alpha=0.3)+
  labs(title="Plot of CI over 100 simulations",
        x =test_label, y = "Estimation")+
  theme(
plot.title = element_text(size=14,hjust = 0.5)
)

```

Diagnostics
```{r}
  mx_deriv1 <- mhat_1(para$n,para$h,test$X,train_label$X,train_label$Y,k,k_1);mx_deriv1
  px <- phat(para$n,para$h,test$X,train_label$X,k);px
  qx <- phat(para$m,para$g,test$X,train_un$X,k);qx

esti_var(para$n,para$h,para$m,para$g,mx_deriv1,sigmaep,px,qx,rk$value,sigmak$value,E_H_ratio = 1)
#var(coverage$esti)
#mean(coverage$sd)^2
```

Find the relationship between bandwidth and coverage probability
```{r}
set.seed(10)

rounds <- 100

hlist <- seq(0.1,1,0.1)
glist <- seq(0.3,4,0.3)

coverage_all <- data.frame()

cover <- 1:rounds

for(i in 1:length(hlist)){
  para$h <- hlist[i]
  for(j in 1:length(glist)){
    para$g <- glist[j]
    for(ep in 1:rounds){
      data <- simu_norm(para$m + para$n, 1, meanx = 0, sigmax = sigmax, sigmaep = sigmaep)
    
      train_label <- data[1:para$n,]
      train_un <- data[(1+para$n):(para$m+para$n),]
      
      temp <- CI(adjust = 1,0.95,para,train_label,train_un,test,sigmaep,rk$value,sigmak$value)
      
      cover[ep] <- (temp$lower <= test$Y)*(temp$upper >= test$Y)
    }
    coverage_all <- rbind(coverage_all,data.frame(h = para$h, g = para$g, cover = mean(cover, na.rm = T)))
  }
}
```

Visualize the relationship between (h, g) and coverage probability
```{r}
plot(hlist,coverage_all$cover[1:length(hlist)],type = "n",pch = 1, ylab = "Coverage Probability", main = "(h,g) and Coverage Probability", ylim = c(0.3,1))
for(i in 1:length(glist)){
  lines(hlist,coverage_all$cover[(1+(i-1)*length(hlist)):(i*length(hlist))], col = i, pch = i ,type = "b")
}
legend("bottomleft", legend = glist,col=1:length(hlist), pch = 1:length(hlist),cex=0.8)
abline(h = 0.95, col = "black")
```

Visualize the performance of estimators: Two dimensional heatmap
```{r}
coverage_all$Error <- abs(coverage_all$cover - 0.95)
heatmap2 <- ggplot(coverage_all, aes(h, g, fill = Error))
heatmap2 + geom_tile()+
  labs(title="Grid Search Result of Coverage Error")+
  theme(plot.title = element_text(size=14,hjust = 0.5))
```

Next, we estimate the error variance. And repeat the previous processes. This is leave one out 
```{r}
esti_error <- function(para,train_label){
  esti <- train_label$Y
  for(i in 1:length(esti)){
    esti[i] <- mhat(para$n,para$h,x = train_label$X[i],X = train_label$X,Y = train_label$Y,k)
  }
  error_esti <- mean((esti - train_label$Y)^2)
  return(error_esti)
}
```

Setup parameters and sample(estimate error)
```{r}
set.seed(30)
para <- paraset_g(64,10/19,rk$value, muk$value)
```

Test the true coverage probability
```{r}
set.seed(10)

rounds <- 100

para$h <- 1 # result_hy$h[HY_opt]
para$g <- 0.3 # result_hy$g[HY_opt]

coverage <- data.frame()

test <- data.frame(X = 2, Y = mx(2))

for(i in 1:rounds){
  data <- simu_norm(para$m + para$n, 1, meanx = 0, sigmax = sigmax, sigmaep = sigmaep)

  train_label <- data[1:para$n,]
  train_un <- data[(1+para$n):(para$m+para$n),]
  sigmaep_esti <- sqrt(esti_error(para,train_label))
  coverage <- rbind(coverage,CI(adjust = 1,0.95,para,train_label,train_un,test,sigmaep_esti,rk$value,sigmak$value))
}

coverage$cover <- (coverage$lower <= test$Y)*(coverage$upper >= test$Y)
mean(coverage$cover,na.rm = T)
```

Draw the plot to show how CI performs
```{r}
plot(coverage$lower, xlab = "Combinations", ylab = "Estimates",col="red", ylim = c(0,10))
points(coverage$upper, col = "blue")
lines(coverage$esti, lty = 2)
abline(h = 4, col = "black")
legend("topright", legend=c("upper bound","lower bound"),col=c("blue","red"), pch = c(1,1),cex=0.8)
```

GGPLOT2
```{r}
test_label <- str_c("n = ", para$n)
ggplot(data = coverage,aes(x = simulation,y = esti)) + 
  geom_line()+
  geom_hline(yintercept = 4)+
  geom_ribbon(aes(ymin=lower,ymax=upper),alpha=0.3)+
  labs(title="Plot of CI over 100 simulations",
        x =test_label, y = "Estimation")+
  theme(
plot.title = element_text(size=14,hjust = 0.5)
)

```

Diagnostics
```{r}
var(coverage$esti)
mean(coverage$sd)^2
```

Find the relationship between bandwidth and coverage probability
```{r}
set.seed(20)

rounds <- 150

hlist <- seq(0.1,1,0.1)
glist <- seq(0.3,3,0.3)

coverage_all <- data.frame()

cover <- 1:rounds

for(i in 1:length(hlist)){
  para$h <- hlist[i]
  for(j in 1:length(glist)){
    para$g <- glist[j]
    for(ep in 1:rounds){
      data <- simu_norm(para$m + para$n, 1, meanx = 0, sigmax = sigmax, sigmaep = sigmaep)
    
      train_label <- data[1:para$n,]
      train_un <- data[(1+para$n):(para$m+para$n),]
      
      temp <- CI(adjust = 1,0.95,para,train_label,train_un,test,sigmaep_esti,rk$value,sigmak$value)
      
      cover[ep] <- (temp$lower <= test$Y)*(temp$upper >= test$Y)
    }
    coverage_all <- rbind(coverage_all,data.frame(h = para$h, g = para$g, cover = mean(cover, na.rm = T)))
  }
}
```

Visualize the relationship between (h, g) and coverage probability
```{r}
plot(hlist,coverage_all$cover[1:length(hlist)],type = "n",pch = 1, ylab = "Coverage Probability", main = "(h,g) and Coverage Probability", ylim = c(0.3,1))
for(i in 1:length(glist)){
  lines(hlist,coverage_all$cover[(1+(i-1)*length(hlist)):(i*length(hlist))], col = i, pch = i ,type = "b")
}
legend("bottomleft", legend = glist,col=1:length(hlist), pch = 1:length(hlist),cex=0.8)
abline(h = 0.95, col = "black")
```

Visualize the performance of estimators: Two dimensional heatmap
```{r}
coverage_all$Error <- abs(coverage_all$cover - 0.95)
arrange(coverage_all,coverage_all$Error)[1:10,]
heatmap3 <- ggplot(coverage_all, aes(h, g, fill = Error))
heatmap3 + geom_tile()+
  labs(title="Grid Search Result of Coverage Error")+
  theme(plot.title = element_text(size=14,hjust = 0.5))
```

Exp3: After exploring the properties of the proposed estimator, we shall provide some methods to find the (h,g) can construct confidence interval. The first method is through the approximated variance.

Although from the equation, we observe that the variance is a decreasing function of g. But to ensure asymptotic properties holds and qhat is precise enough, g need to be small enough. We here choose it to be (8*pi^(1/2)/3)^(1/5)*sd(train_label$X)*(rk$value/muk$value^2/(para$m))^(1/5), which is approximated the best choice for "kernel density estimator".
```{r}
h_opt_esti <- function(para,train_label,train_un,test,sigmaep_esti,rk,sigmak,E_H_ratio = 1){
  mx_deriv1 <- mhat_1(para$n,para$h,test$X,train_label$X,train_label$Y,k,k_1)
  h_opt <- (sigmaep_esti^2*rk$value/(4*mx_deriv1^2*sigmak$value))^(1/5)*(para$m*para$g^3)^(1/5)*para$n^(-1/5)
  return(h_opt)
}
```

```{r}
set.seed(50)
para <- paraset_g(64,10/19,rk$value, muk$value)

data <- simu_norm(para$m + para$n, 1, meanx = 0, sigmax = sigmax, sigmaep = sigmaep)

train_label <- data[1:para$n,]
train_un <- data[(1+para$n):(para$m+para$n),]

para$g <- (8*pi^(1/2)/3)^(1/5)*sd(train_label$X)*(rk$value/muk$value^2/para$m)^(1/5)

sigmaep_esti <- sqrt(esti_error(para,train_label))

h_opt <- h_opt_esti(para,train_label,train_un,test,sigmaep_esti,rk,sigmak);h_opt
```

Test the true coverage probability
```{r}
set.seed(60)

rounds <- 200

para <- paraset_g(64,10/19,rk$value, muk$value)

coverage_exp3 <- data.frame()

test <- data.frame(X = 2, Y = mx(2))

for(i in 1:rounds){
  data <- simu_norm(para$m + para$n, 1, meanx = 0, sigmax = sigmax, sigmaep = sigmaep)
  para <- paraset_g(para$n,10/19,rk$value, muk$value)
  train_label <- data[1:para$n,]
  train_un <- data[(1+para$n):(para$m+para$n),]
  para$g <- (8*pi^(1/2)/3)^(1/5)*sd(train_label$X)*(rk$value/muk$value^2/para$m)^(1/5)
  sigmaep_esti <- sqrt(esti_error(para,train_label))
  para$h <- h_opt_esti(para,train_label,train_un,test,sigmaep_esti,rk,sigmak)
  coverage_exp3 <- rbind(coverage_exp3,CI(adjust = 1,0.95,para,train_label,train_un,test,sigmaep_esti,rk$value,sigmak$value))
}

coverage_exp3$cover <- (coverage_exp3$lower <= test$Y)*(coverage_exp3$upper >= test$Y)
mean(coverage_exp3$cover,na.rm = T)
```

GGPLOT2: From the plots, we can see that the choice of g is quite large. I suspect that this is because of the large variance of g. I will now change sigmax to 1. The finding is interesting, coverage probability now is increasing with n and m. 
```{r}
simulation <- 1:rounds
test_label <- str_c("n = ", para$n)
ggplot(data = coverage_exp3,aes(x = simulation,y = esti)) + 
  geom_line()+
  geom_hline(yintercept = 4)+
  geom_ribbon(aes(ymin=lower,ymax=upper),alpha=0.3)+
  labs(title="Plot of CI over 100 simulations",
        x =test_label, y = "Estimation")+
  theme(
plot.title = element_text(size=14,hjust = 0.5)
)
```


Exp4: After exploring the properties of the proposed estimator, we shall provide some methods to find the (h,g) can construct confidence interval. The second method is through resampling and cross-validation.

First generate sample.
```{r}
set.seed(30)

para <- paraset_g(32,10/19,rk$value, muk$value)

data <- simu_norm(para$n + para$m, 1, meanx = 0, sigmax = sigmax, sigmaep = sigmaep)

para$h <- (8*pi^(1/2)/3)^(1/5)*sd(data$X)*(rk$value/muk$value^2/para$n)^(1/5)

para$g <- (8*pi^(1/2)/3)^(1/5)*sd(data$X)*(rk$value/muk$value^2/para$m)^(1/5)

train_label <- data[1:para$n,]

train_un <- data[(1+para$n):(para$m+para$n),]

test <- data.frame(X = 2,Y = mx(2))
```

Secondly, prepare for bootstrap.
```{r}
hlist <- seq(0.1,4,0.1)
mse_min <- 10000
h_opt <- 0.1
for(h in hlist){
  mse <- 0
  for(exp in 1:nrow(train_label)){
      
      test <- train_label[exp,]
      
      train_label_loo <- train_label[-exp,]
      
      esti <- mhat(n = para$n,h = h,x = test$X,X = train_label_loo$X,Y = train_label_loo$Y,k)
      
      mse <- mse + (esti - test$Y)^2
  }
  print(mse)
  if(mse < mse_min){
    mse_min <- mse
    h_opt <- h
  }
}
```
Find the best estimation of px, qx, m(x) and m'(x) in order to do bootstrap.
```{r}
para$h <- (8*pi^(1/2)/3)^(1/5)*sd(data$X)*(rk$value/muk$value^2/para$n)^(1/5)
px <- phat(para$n,para$h,test$X,data$X,k)
qx <- px

labeled <- nw_simu(data[1:para$n,],data[1:para$n,],para$n,h_opt,k)$esti
names(labeled) <- c("X","Y")
error <- labeled$Y - data[1:para$n,]$Y
error <- error - mean(error)
unlabeled <- data[(1+para$n):(para$n+para$m),]
sigmaep_esti <- sqrt(sd(error))
test_x <- 1
test <- data.frame(X = test_x, Y = mhat(n = para$n,h = h_opt,x = test_x,X = data[1:para$n,]$X,Y = data[1:para$n,]$Y,k))
mx_deriv1 <- mhat_1(para$n,h_opt,test$X,data[1:para$n,]$X,data[1:para$n,]$Y,k,k_1)
```

Testing Bootstrap
```{r}
train_label <- labeled[sample(1:nrow(labeled), para$n,replace = T),]
train_un <- unlabeled[sample(1:nrow(unlabeled), para$m,replace = T),]
train_label$Y <- train_label$Y + error[sample(1:length(error), para$n,replace = T)]
esti <- nw_simu(train_label,train_label,para$n,para$h,k)$esti
plot(train_label$X,train_label$Y)
points(data$X,data$X^2,col = "red")
points(esti$X,esti$esti_nw,col = "blue")
```

Select the (h,g) with best coverage: Bootstrap
```{r}
hlist <- seq(0.1,1,0.1)
glist <- seq(0.3,3,0.3)

rounds <- 250

coverage <- data.frame()
result_ci <- data.frame()

for(i in 1:length(hlist)){
  for(j in 1:length(glist)){
      coverage <- data.frame()
      set.seed(10)
    for(exp in 1:rounds){

      train_label <- labeled
      train_label$Y <- train_label$Y + error[sample(1:length(error), para$n,replace = T)]
      
      para$h <- hlist[i]
      para$g <- glist[j]
      
      coverage <- rbind(coverage,CI(0.95,mx_deriv1,para,train_label,train_un,test,px,qx,sigmaep_esti,rk$value,sigmak$value))
    }
    cover <- (coverage$lower <= test$Y)*(coverage$upper >= test$Y)
    
    cover_prop <- mean(cover,na.rm = T)
      
    result_ci <- rbind(result_ci, data.frame(h = para$h, g = para$g, cover_prop, sd = sqrt(mean(coverage$sd^2))))
  }
}
result_ci$error <- abs(result_ci$cover_prop - 0.95)
```

Select the (h,g) with best coverage: leave one out cross validation. There is one huge drawback of this method. It does not take into consideration the mse or accuracy of length of CI. 
```{r}
loocv <- function(para,hlist, glist, train_label, train_un){

  result_ci <- data.frame()

  for(i in 1:length(hlist)){
  for(j in 1:length(glist)){
      coverage <- data.frame()
      para$h <- hlist[i]
      para$g <- glist[j]
    for(exp in 1:nrow(train_label)){
      
      test <- train_label[exp,]
      
      train_label_loo <- train_label[-exp,]
      
      sigmaep_esti <- sqrt(esti_error(para,train_label_loo))
      
      coverage <- rbind(coverage,CI(adjust = 1,0.95,para,train_label_loo,train_un,test,sigmaep_esti,rk$value,sigmak$value))
    }
    coverage <- cbind(coverage, train_label)
    cover <- (coverage$lower <= train_label$Y)*(coverage$upper >= train_label$Y)
    
    cover_prop <- mean(cover,na.rm = T)
    
    result_ci <- rbind(result_ci, data.frame(h = para$h, g = para$g, cover_prop, msd = sqrt(mean(coverage$sd^2))))
  }
  }
  result_ci$error <- abs(result_ci$cover_prop - 0.95)
  
  best <- result_ci[match(min(result_ci$error),result_ci$error),]
  
  return(best)
}

```

Test the true coverage of the chosen (h,g) according to loocv
```{r}
set.seed(60)

rounds <- 20

para <- paraset_g(64,10/19,rk$value, muk$value)
test <- data.frame(X = 2, Y = mx(2))

hlist <- seq(0.1,1,0.1)
glist <- seq(0.3,3,0.3)

coverage_exp4 <- data.frame()

for(i in 1:rounds){
  data <- simu_norm(para$m + para$n, 1, meanx = 0, sigmax = sigmax, sigmaep = sigmaep)
  train_label <- data[1:para$n,]
  train_un <- data[(1+para$n):(para$m+para$n),]
  
  best <- loocv(para,hlist,glist,train_label,train_un)
  
  sigmaep_esti <- sqrt(esti_error(para,train_label))
  
  para$h <- best$h
  
  para$g <- best$g
  
  coverage_exp4 <- rbind(coverage_exp4,CI(adjust = 1,0.95,para,train_label,train_un,test,sigmaep_esti,rk$value,sigmak$value))
}

coverage_exp4$cover <- (coverage_exp4$lower <= test$Y)*(coverage_exp4$upper >= test$Y)
mean(coverage_exp4$cover,na.rm = T)
```

Visualize the performance of estimators: Two dimensional heatmap
```{r}
#result_ci$true_cover <- coverage_all$cover
arrange(result_ci,result_ci$error)[1:10,]
heatmap4 <- ggplot(result_ci, aes(h, g, fill = error))
heatmap4 + geom_tile()
```

avoid setting h too small when the data is sparse. Redefine phat so not fall below the constant.
Common approach to avoid Computational issue

Possible Conclusion: the choice of h and g matters and our choice should depend on our goal, i.e., whether we want better confidence interval or smaller mse.